{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Improving Semantic Water Segmentation by Fusing Sentinel-1 Intensity and Interferometric Synthetic Aperture Radar\n",
    "### (InSAR) Coherence Data\n",
    "\n",
    "**Author: Ernesto Colon**\n",
    "**The Cooper Union for the Advancement of Science and Art**\n",
    "\n",
    "#### Attention U-Net Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import metrics_utils\n",
    "from utils import dataset_gen\n",
    "from utils import general_utils\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from keras_unet_collection import models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load previously saved dataset splits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define dictionary with filepaths\n",
    "base_dir = \"base_dir_path\"\n",
    "\n",
    "train_val_test_pths = {'train_fn_df' : f\"{base_dir}\\\\ds_train_split_10m.csv\",\n",
    "                       'val_fn_df' : f\"{base_dir}\\\\ds_val_split_10m.csv\",\n",
    "                       'test_fn_df' : f\"{base_dir}\\\\ds_test_split_10m.csv\"}\n",
    "\n",
    "# Load csv files with train / val / test splits into dataframes\n",
    "train_val_fn_df, test_fn_df, train_size, val_size, test_size =\\\n",
    "    dataset_gen.unet_load_ds_df(train_val_test_pths['train_fn_df'],\n",
    "                                train_val_test_pths['val_fn_df'],\n",
    "                                train_val_test_pths['test_fn_df'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define category names and a color mapping for semantic segmentation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define category names\n",
    "tgt_cat_names = {\n",
    "    0: 'Not water',\n",
    "    1: 'Water'\n",
    "}\n",
    "\n",
    "# Define the colors per category\n",
    "wtr_clrs_hex = ['#f7f7f7', '#67a9cf']\n",
    "\n",
    "# Generate the labels colormap\n",
    "wtr_cmap = general_utils.gen_cmap(wtr_clrs_hex)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate data sets for inference\n",
    "\n",
    "We generate datasets for the following scenarios:\n",
    "\n",
    "- Scenario 1: Co-event intensity data only\n",
    "- Scenario 2: Pre- and co-event intensity data only\n",
    "- Scenario 3: Pre- and co-event intensity and coherence data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define dictionaries to hold the datasets - the keys will be the different scenarios\n",
    "X_train_dict = {}\n",
    "Y_train_dict = {}\n",
    "\n",
    "X_val_dict = {}\n",
    "Y_val_dict = {}\n",
    "\n",
    "X_test_dict = {}\n",
    "Y_test_dict = {}\n",
    "\n",
    "Y_pred_dict = {}\n",
    "\n",
    "# Define scenario number to scenario name mapping\n",
    "scenario_dict = {1: 'co_event_intensity_only',\n",
    "                 2: 'pre_co_event_intensity',\n",
    "                 3: 'pre_co_event_int_coh'}\n",
    "\n",
    "scenario_num_bands = {1: 2,\n",
    "                      2: 4,\n",
    "                      3: 6}\n",
    "\n",
    "# Define the number of bands per scenario\n",
    "num_bands_dict = {'co_event_intensity_only': 2,\n",
    "                 'pre_co_event_intensity': 4,\n",
    "                 'pre_co_event_int_coh': 6}\n",
    "\n",
    "IMG_SIZE = 512\n",
    "\n",
    "# define dictionaries to hold the datasets\n",
    "train_val_samples_dict = {}\n",
    "test_samples_dict = {}\n",
    "\n",
    "# Loop through each scenario and create the tensorflow data loaders\n",
    "scenarios = [1, 2, 3]\n",
    "\n",
    "for scenario in scenarios:\n",
    "\n",
    "    # Create the samples list given the dataframes with file paths as input\n",
    "    train_val_samples_dict[f\"scenario_{scenario}\"], test_samples_dict[f\"scenario_{scenario}\"] = \\\n",
    "        dataset_gen.create_samples_list({'scenario': scenario_dict[scenario],\n",
    "                                            'test_df': test_fn_df,\n",
    "                                            'train_val_df': train_val_fn_df})\n",
    "\n",
    "    # Create data sets dictionary\n",
    "    X_train_dict[f\"scenario_{scenario}\"], X_val_dict[f\"scenario_{scenario}\"], X_test_dict[f\"scenario_{scenario}\"] =\\\n",
    "        dataset_gen.unet_ds_creation({'train_val_list': train_val_samples_dict[f\"scenario_{scenario}\"],\n",
    "                                      'test_list': test_samples_dict[f\"scenario_{scenario}\"]})\n",
    "\n",
    "    # Batch the tensorflow train, val, and test data set generators\n",
    "    X_train_dict[f\"scenario_{scenario}\"] =\\\n",
    "        X_train_dict[f\"scenario_{scenario}\"].batch(10).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    X_val_dict[f\"scenario_{scenario}\"] =\\\n",
    "        X_val_dict[f\"scenario_{scenario}\"].batch(10).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    X_test_dict[f\"scenario_{scenario}\"] = X_test_dict[f\"scenario_{scenario}\"].batch(1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Hand Labeled Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load hand label dataset\n",
    "hand_lbl_ds_pth = \"hand_lbl_ds_pth\"\n",
    "hand_lbl_ds_fname = f\"{hand_lbl_ds_pth}hand_lbl_ds_10m_res.csv\"\n",
    "\n",
    "df_hand_lbl_samples = pd.read_csv(hand_lbl_ds_fname)\n",
    "\n",
    "# loop through df and append sample paths to a list\n",
    "hand_samples = list()\n",
    "\n",
    "for idx, row in df_hand_lbl_samples.iterrows():\n",
    "    hand_samples.append((row['s1'], row['pre_event_grd'], row['pre_event_coh'], row['co_event_coh'], row['hand_lbl']))\n",
    "\n",
    "\n",
    "hand_lbl_test_samples = dict()\n",
    "\n",
    "for scenario in scenarios:\n",
    "    hand_lbl_test_samples[f\"scenario_{scenario}_hand_lbl\"] =\\\n",
    "        dataset_gen.create_samples_list_hand_lbl({'scenario': scenario_dict[scenario], 'test_df': df_hand_lbl_samples})\n",
    "\n",
    "    X_test_dict[f\"scenario_{scenario}_hand_lbl\"] =\\\n",
    "        dataset_gen.ds_creation_hand_lbl({'test_list': hand_lbl_test_samples[f\"scenario_{scenario}_hand_lbl\"]})\n",
    "\n",
    "    X_test_dict[f\"scenario_{scenario}_hand_lbl\"] = X_test_dict[f\"scenario_{scenario}_hand_lbl\"].batch(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Attention U-Net Models\n",
    "\n",
    "For this study, we leverage the publicly available Keras UNet Collection linked below.\n",
    "\n",
    "https://github.com/yingkaisha/keras-unet-collection\n",
    "\n",
    "**Load previously saved model weights**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "IMG_SIZE = 512\n",
    "\n",
    "attn_unet_models_dir = {'scenario_1': \"model_scen_1_weights_pth\",\n",
    "                        'scenario_2': \"model_scen_2_weights_pth\",\n",
    "                        'scenario_3': \"model_scen_3_weights_pth\"}\n",
    "\n",
    "attn_unet_models_dict = dict()\n",
    "\n",
    "for scenario in scenarios:\n",
    "    attn_unet_models_dict[f\"scenario_{scenario}\"] =\\\n",
    "        models.att_unet_2d((IMG_SIZE, IMG_SIZE, scenario_num_bands[scenario]),\n",
    "                           filter_num=[64, 128, 256, 512, 1024],\n",
    "                           n_labels=2,\n",
    "                           stack_num_down=2,\n",
    "                           stack_num_up=2,\n",
    "                           activation='ReLU',\n",
    "                           atten_activation='ReLU',\n",
    "                           attention='add',\n",
    "                           output_activation='Sigmoid',\n",
    "                           batch_norm=True,\n",
    "                           pool=False,\n",
    "                           unpool=False,\n",
    "                           backbone='VGG16',\n",
    "                           weights=None,\n",
    "                           freeze_backbone=True,\n",
    "                           freeze_batch_norm=True,\n",
    "                           name='attunet')\n",
    "\n",
    "    # restore the weights\n",
    "    print(f\"Loading weights for scenario: {scenario}...\\n\")\n",
    "    attn_unet_models_dict[f\"scenario_{scenario}\"].load_weights(attn_unet_models_dir[f\"scenario_{scenario}\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# wrapping the predictions routine into a function\n",
    "def u_net_inference(x_test_ds, test_size, model):\n",
    "    \"\"\"\n",
    "    Function to make inferences using tensorflow\n",
    "\n",
    "    :param x_test_ds: tensorflow dataset pipeline for testing\n",
    "    :param test_size: number of test images in our pipeline\n",
    "    :param model: tensorflow model for inference\n",
    "    :return: y_test and y_pred are ndarrays with shape (num_pix,)\n",
    "    \"\"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Compute predictions at the same time to avoid a random shift\n",
    "    test_tgts_list = []\n",
    "    pred_tgts_list = []\n",
    "\n",
    "    for img, tgt, weights in x_test_ds.take(test_size):\n",
    "        pred = metrics_utils.create_mask(model.predict(img))\n",
    "        pred_tgts_list.append(np.squeeze(pred))\n",
    "\n",
    "        test_tgts_list.append(np.squeeze(tgt.numpy()))\n",
    "\n",
    "    y_test = np.stack(test_tgts_list, axis=-1).flatten()\n",
    "    y_pred = np.stack(pred_tgts_list, axis=-1).flatten()\n",
    "\n",
    "    print(f\"Inference took: {time.time() - start_time} seconds\\n\")\n",
    "\n",
    "    return y_test, y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Predicting on held-out test set and hand-labeled test set**\n",
    "\n",
    "**Notes**\n",
    "\n",
    "The held-out test set is comprised of Sentinel-2 weak labels from the Sen1Floods11 data set.\n",
    "\n",
    "The hand-labeled data set is also provided by the Sen1Floods11 data set, and provides an independent data set not\n",
    "used during training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# loop through each scenario\n",
    "for scenario in scenarios:\n",
    "\n",
    "    # Held-out dataset predictions\n",
    "    print(f\"Predicting on held-out test dataset for scenario: {scenario}...\\n\")\n",
    "    Y_test_dict[f\"scenario_{scenario}\"], Y_pred_dict[f\"scenario_{scenario}\"] =\\\n",
    "        u_net_inference(X_test_dict[f\"scenario_{scenario}\"],\n",
    "                        test_size,\n",
    "                        attn_unet_models_dict[f\"scenario_{scenario}\"])\n",
    "\n",
    "    # Hand-labeled dataset predictions\n",
    "    print(f\"Predicting on hand-labeled test dataset for scenario: {scenario}...\\n\")\n",
    "    Y_test_dict[f\"scenario_{scenario}_hand_lbl\"], Y_pred_dict[f\"scenario_{scenario}_hand_lbl\"] =\\\n",
    "        u_net_inference(X_test_dict[f\"scenario_{scenario}_hand_lbl\"],\n",
    "                        test_size,\n",
    "                        attn_unet_models_dict[f\"scenario_{scenario}\"])\n",
    "\n",
    "print(f\"\\n\\nTotal inference took: {time.time() - start_time} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compute Metrics\n",
    "\n",
    "For metrics, we compute:\n",
    "\n",
    "- Overall accuracy\n",
    "- Mean intersection over union, mIoU\n",
    "- Jaccard score\n",
    "- Water precision\n",
    "- Water recall\n",
    "- Water f1-score\n",
    "- Not-Water precision\n",
    "- Not-Water recall\n",
    "- Not-Water f1-score\n",
    "\n",
    "#### Held-out Test Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "summary_df = metrics_utils.summary_report(Y_test_dict, Y_pred_dict)\n",
    "\n",
    "print(f\"\\n\\nProcess took: {time.time() - start_time} seconds\")\n",
    "\n",
    "# save summary to csv file\n",
    "attn_unet_summ_pth = \"attn_unet_summ_pth\"\n",
    "fname = \"attn_unet_10m_summary_stats.csv\"\n",
    "summary_df.to_csv(f\"{attn_unet_summ_pth}\\\\{fname}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Computing IoU per class (i.e., water and not-water)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "miou_per_class = metrics_utils.miou_per_class(Y_test_dict, Y_pred_dict)\n",
    "\n",
    "# save to csv file\n",
    "mIou_fname = \"attn_unet_10m_mIoU_per_class_stats.csv\"\n",
    "miou_per_class.to_csv(f\"{attn_unet_summ_pth}\\\\{mIou_fname}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing Models' Ability to Generalize\n",
    "\n",
    "We use data over the Sri-Lanka region (both weakly labeled and hand-labeled) to test the models' ability\n",
    "to generalize\n",
    "\n",
    "#### Generate generalization data set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generalization_ds_pth = \"generalization_ds_pth\"\n",
    "\n",
    "# create empty list to store the samples' path\n",
    "gen_test_samples = []\n",
    "\n",
    "# load csv file into dataframe\n",
    "gen_test_fn_df = pd.read_csv(generalization_ds_pth)\n",
    "\n",
    "# grab number of samples in the data set\n",
    "num_gen_samp = len(gen_test_samples)\n",
    "\n",
    "# create dictionaries to store the tensorflow data loaders\n",
    "gener_test_samples = {}\n",
    "\n",
    "gener_X_test_dict = dict()\n",
    "gener_Y_test_dict = dict()\n",
    "\n",
    "\n",
    "for scenario in scenarios:\n",
    "    gener_test_samples[f\"scenario_{scenario}\"] =\\\n",
    "        dataset_gen.create_samples_list_hand_lbl({'scenario': scenario_dict[scenario], 'test_df': gen_test_fn_df})\n",
    "\n",
    "    gener_X_test_dict[f\"scenario_{scenario}\"] =\\\n",
    "        dataset_gen.ds_creation_hand_lbl({'test_list': gener_test_samples[f\"scenario_{scenario}\"]})\n",
    "\n",
    "    gener_X_test_dict[f\"scenario_{scenario}\"] = gener_X_test_dict[f\"scenario_{scenario}\"].batch(1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Hand-Labeled Generalization Data Set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load hand-labeled dataset\n",
    "gen_hand_lbl_ds_pth = \"gen_hand_lbl_ds_pth\"\n",
    "\n",
    "# read hand-labeled data set into dataframe\n",
    "gen_hand_lbl_df = pd.read_csv(gen_hand_lbl_ds_pth)\n",
    "\n",
    "# create dict to store tensorflow data loaders\n",
    "gen_hand_samples_by_region_dict = {}\n",
    "\n",
    "# loop through each scenario and create the tensorflow dat loaders\n",
    "for scenario in scenarios:\n",
    "    gener_test_samples[f\"scenario_{scenario}_hand_lbl\"] =\\\n",
    "        dataset_gen.create_samples_list_hand_lbl({'scenario': scenario_dict[scenario],'test_df': gen_hand_lbl_df})\n",
    "\n",
    "    gener_X_test_dict[f\"scenario_{scenario}_hand_lbl\"] = dataset_gen.ds_creation_hand_lbl({'test_list': gener_test_samples[f\"scenario_{scenario}_hand_lbl\"]})\n",
    "    gener_X_test_dict[f\"scenario_{scenario}_hand_lbl\"] = gener_X_test_dict[f\"scenario_{scenario}_hand_lbl\"].batch(1)\n",
    "\n",
    "# grab the generalization data set's size\n",
    "gener_hand_lbl_test_size = gen_hand_lbl_df.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Make Predictions on the Generalization Data Set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create dictionary to store the generalization data set's predictions\n",
    "gener_Y_pred_dict = dict()\n",
    "\n",
    "# Keep track of how long inference takes\n",
    "start_time = time.time()\n",
    "\n",
    "for scenario in scenarios:\n",
    "\n",
    "    # Held-out dataset predictions\n",
    "    print(f\"Predicting on held-out test dataset for scenario: {scenario}...\\n\")\n",
    "    gener_Y_test_dict[f\"scenario_{scenario}\"], gener_Y_pred_dict[f\"scenario_{scenario}\"] =\\\n",
    "        u_net_inference(gener_X_test_dict[f\"scenario_{scenario}\"],\n",
    "                        gener_hand_lbl_test_size,\n",
    "                        attn_unet_models_dict[f\"scenario_{scenario}\"])\n",
    "\n",
    "    # Hand-labeled dataset predictions\n",
    "    print(f\"Predicting on hand-labeled test dataset for scenario: {scenario}...\\n\")\n",
    "    gener_Y_test_dict[f\"scenario_{scenario}_hand_lbl\"], gener_Y_pred_dict[f\"scenario_{scenario}_hand_lbl\"] =\\\n",
    "        u_net_inference(gener_X_test_dict[f\"scenario_{scenario}_hand_lbl\"],\n",
    "                        gener_hand_lbl_test_size,\n",
    "                        attn_unet_models_dict[f\"scenario_{scenario}\"])\n",
    "\n",
    "print(f\"\\n\\nTotal inference took: {time.time() - start_time} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compute Metrics for Generalization Data Set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stat_time = time.time()\n",
    "\n",
    "# Generate metrics\n",
    "gener_summary_df = metrics_utils.summary_report(gener_Y_test_dict, gener_Y_pred_dict)\n",
    "\n",
    "print(f\"\\n\\nProcess took: {time.time() - start_time} seconds\")\n",
    "\n",
    "# save the metrics to a csv file for later recall\n",
    "gener_summ_fname = \"attn_unet_10m_generalization_stats.csv\"\n",
    "gener_summary_df.to_csv(f\"{attn_unet_summ_pth}\\\\{gener_summ_fname}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Compute IoU per class for generalization dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gener_miou_per_class = metrics_utils.miou_per_class(gener_Y_test_dict, gener_Y_pred_dict)\n",
    "\n",
    "# save to csv\n",
    "gener_miou_fname = \"attn_unet_10m_generalization_mIoU_stats.csv\"\n",
    "gener_miou_per_class.to_csv(f\"{attn_unet_summ_pth}\\\\{gener_miou_fname}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Making Inferences Aggregated by Geographical Region"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for scenario in scenarios:\n",
    "    gener_test_samples[f\"scenario_{scenario}\"] =\\\n",
    "        dataset_gen.create_samples_list_hand_lbl({'scenario': scenario_dict[scenario], 'test_df': gen_test_fn_df})\n",
    "\n",
    "    gener_X_test_dict[f\"scenario_{scenario}\"] =\\\n",
    "        dataset_gen.ds_creation_hand_lbl({'test_list': gener_test_samples[f\"scenario_{scenario}\"]})\n",
    "\n",
    "    gener_X_test_dict[f\"scenario_{scenario}\"] = gener_X_test_dict[f\"scenario_{scenario}\"].batch(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_samples_by_region_dict = {}\n",
    "\n",
    "# Define the regions excluding the generalization region\n",
    "regions = ['USA', 'Mekong', 'Colombia', 'Paraguay', 'India', 'Bolivia']\n",
    "\n",
    "# create dictionary schema to hold the tensorflow data loaders aggregated by region\n",
    "X_test_ds_region_dict = {region: {} for region in regions}\n",
    "\n",
    "ds_test_size_region = {}\n",
    "\n",
    "# loop through each of the regions\n",
    "for region in regions:\n",
    "    # temp list to store the file paths\n",
    "    pths = list()\n",
    "\n",
    "    # pluck the test sample paths by region\n",
    "    test_pth_region = test_fn_df[test_fn_df.s1.str.contains(region)]\n",
    "\n",
    "    ds_test_size_region[region] = test_pth_region.shape[0]\n",
    "\n",
    "    for scenario in scenarios:\n",
    "        region_test_samples = dataset_gen.create_samples_list_hand_lbl({'scenario': scenario_dict[scenario],\n",
    "                             'test_df': test_pth_region})\n",
    "\n",
    "        X_test_ds_region_dict[region][f\"scenario_{scenario}\"] =\\\n",
    "            dataset_gen.ds_creation_hand_lbl({'test_list': region_test_samples})\n",
    "\n",
    "        X_test_ds_region_dict[region][f\"scenario_{scenario}\"] =\\\n",
    "            X_test_ds_region_dict[region][f\"scenario_{scenario}\"].batch(1)\n",
    "\n",
    "\n",
    "# Hand-labeled data set aggregated by region\n",
    "hand_lbl_ds_test_size_region = {}\n",
    "\n",
    "for region in regions:\n",
    "    # temp list to store the file paths\n",
    "    pths = list()\n",
    "\n",
    "    # pluck the test sample paths by region\n",
    "    test_pth_region = df_hand_lbl_samples[df_hand_lbl_samples.s1.str.contains(region)]\n",
    "\n",
    "    hand_lbl_ds_test_size_region[region] = test_pth_region.shape[0]\n",
    "\n",
    "    for scenario in scenarios:\n",
    "        region_test_samples = dataset_gen.create_samples_list_hand_lbl({'scenario': scenario_dict[scenario],\n",
    "                             'test_df': test_pth_region})\n",
    "\n",
    "        X_test_ds_region_dict[region][f\"scenario_{scenario}_hand_lbl\"] =\\\n",
    "            dataset_gen.ds_creation_hand_lbl({'test_list': region_test_samples})\n",
    "\n",
    "        X_test_ds_region_dict[region][f\"scenario_{scenario}_hand_lbl\"] =\\\n",
    "            X_test_ds_region_dict[region][f\"scenario_{scenario}_hand_lbl\"].batch(1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compute inferences aggregated by region"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create dicts to store predictions and ground truth\n",
    "Y_pred_region_dict = {region : {} for region in regions}\n",
    "Y_test_region_dict = {region : {} for region in regions}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for region in regions:\n",
    "    for scenario in scenarios:\n",
    "\n",
    "        # Held-out dataset predictions\n",
    "        print(f\"Predicting on held-out test dataset for region: {region}, scenario: {scenario}...\\n\")\n",
    "        Y_test_region_dict[region][f\"scenario_{scenario}\"], Y_pred_region_dict[region][f\"scenario_{scenario}\"] =\\\n",
    "            u_net_inference(X_test_ds_region_dict[region][f\"scenario_{scenario}\"],\n",
    "                            ds_test_size_region[region],\n",
    "                            attn_unet_models_dict[f\"scenario_{scenario}\"])\n",
    "\n",
    "        # Hand-labeled dataset predictions\n",
    "        if region == 'Colombia':\n",
    "            continue    # The Sen1Floods11 data set does not have hand-labels for Colombia\n",
    "        else:\n",
    "            print(f\"Predicting on hand-labeled test dataset for region:{region}, scenario: {scenario}...\\n\")\n",
    "            Y_test_region_dict[region][f\"scenario_{scenario}_hand_lbl\"],\\\n",
    "            Y_pred_region_dict[region][f\"scenario_{scenario}_hand_lbl\"] =\\\n",
    "                u_net_inference(X_test_ds_region_dict[region][f\"scenario_{scenario}_hand_lbl\"],\n",
    "                                hand_lbl_ds_test_size_region[region],\n",
    "                                attn_unet_models_dict[f\"scenario_{scenario}\"])\n",
    "\n",
    "print(f\"\\n\\nTotal inference took: {time.time() - start_time} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Generate prediction summaries / metrics by region"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "summary_by_region = {}\n",
    "\n",
    "for region in regions:\n",
    "    print(f\"Region: {region}\\n\\n\")\n",
    "    summary_by_region[region] = metrics_utils.summary_report(Y_test_region_dict[region], Y_pred_region_dict[region])\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    # save to csv\n",
    "    summary_by_region[region].to_csv(f\"{attn_unet_summ_pth}\\\\{region}_summary_stats.csv\")\n",
    "\n",
    "print(f\"\\n\\nProcess took: {time.time() - start_time} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Compute IoU per class aggregated by region"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regional_miou_per_class = {}\n",
    "\n",
    "for region in regions:\n",
    "    print(f\"Region: {region}\\n\\n\")\n",
    "\n",
    "    regional_miou_per_class[region] =\\\n",
    "        metrics_utils.miou_per_class(Y_test_region_dict[region], Y_pred_region_dict[region])\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    # save to csv\n",
    "    regional_miou_per_class[region].to_csv(f\"{attn_unet_summ_pth}\\\\{region}_mIoU_stats.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Generate labels and label overlap by region"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Combine the generalization data set predictions and ground truth with the rest of the data set\n",
    "Y_pred_region_dict['Sri-Lanka'] = gener_Y_pred_dict\n",
    "\n",
    "Y_test_region_dict['Sri-Lanka'] = gener_Y_test_dict\n",
    "\n",
    "X_test_ds_region_dict['Sri-Lanka'] = gener_X_test_dict\n",
    "\n",
    "# regions with hand-labels\n",
    "all_regions = ['USA', 'Mekong', 'India', 'Bolivia', 'Paraguay', 'Sri-Lanka']\n",
    "Y_pred_hand_lbl_by_region = {}\n",
    "Y_true_hand_lbl_by_region = {}\n",
    "\n",
    "# scenarios to pluck\n",
    "scen_to_pluck = ['scenario_1_hand_lbl', 'scenario_2_hand_lbl', 'scenario_3_hand_lbl']\n",
    "\n",
    "# create schemas to store predictions and ground truth\n",
    "Y_pred_hand_lbl_by_region = {region : {scen : [] for scen in scen_to_pluck} for region in all_regions}\n",
    "Y_true_hand_lbl_by_region = {region : {scen : [] for scen in scen_to_pluck} for region in all_regions}\n",
    "\n",
    "X_test_hand_lbl_by_region = {}\n",
    "X_test_hand_lbl_by_region = {region : {scen : [] for scen in scen_to_pluck} for region in all_regions}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, loop through the test data set and grab all the image rasters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for region in all_regions:\n",
    "    for scen in scen_to_pluck:\n",
    "        ds_len = X_test_ds_region_dict[region][scen].cardinality().numpy()\n",
    "        print(f\"region: {region}, scen: {scen}, len: {ds_len}\")\n",
    "        img_lst = list()\n",
    "        for img, tgt, weight in X_test_ds_region_dict[region][scen].take(ds_len):\n",
    "            img_lst.append(np.squeeze(img.numpy()))\n",
    "\n",
    "        X_test_hand_lbl_by_region[region][scen] = np.stack(img_lst, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Copy the predictions and the ground truth labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for region in all_regions:\n",
    "    for scen in scen_to_pluck:\n",
    "        Y_pred_hand_lbl_by_region[region][scen] = Y_pred_region_dict[region][scen].copy()\n",
    "\n",
    "        Y_true_hand_lbl_by_region[region][scen] = Y_test_region_dict[region][scen].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create function to generate the label overlap between ground truth and predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_size = 512\n",
    "\n",
    "def gen_lbl_overlap(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to return a semantic map with a label overlap given ground truth and predicted labels\n",
    "    :param y_true: ndarray with ground truth labels\n",
    "    :param y_pred: ndarray with predicted labels\n",
    "    :return: combined, an ndarray with 4 classes (1: true positive, 2: true negatives, 3: false positives, 4: false neg)\n",
    "    \"\"\"\n",
    "\n",
    "    # allocate space to store the label overlap\n",
    "    combined = np.zeros(y_pred.shape)\n",
    "\n",
    "    # true positives are labels that are predicted as water (1)\n",
    "    tp = np.logical_and(np.where(y_pred == 1, 1, 0), np.where(y_true == 1, 1, 0))\n",
    "\n",
    "    # true negatives\n",
    "    tn = np.logical_and(np.where(y_pred == 0, 1, 0), np.where(y_true == 0, 1, 0))\n",
    "\n",
    "    # false positives are labels that were labeled as 1 but that were 0 in reality\n",
    "    fp = np.logical_and(np.where(y_pred == 1, 1, 0), np.where(y_true == 0, 1, 0))\n",
    "\n",
    "    # false negatives are labels that were labeled as 0 but were 1 in reality\n",
    "    fn = np.logical_and(np.where(y_pred == 0, 1, 0), np.where(y_true == 1, 1, 0))\n",
    "\n",
    "    # combine all classes\n",
    "    combined[tp] = 1\n",
    "    combined[tn] = 2\n",
    "    combined[fp] = 3\n",
    "    combined[fn] = 4\n",
    "\n",
    "    return combined"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compute label overlap by region"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lbl_ovrlap_by_region = {region : {scen : [] for scen in scen_to_pluck} for region in all_regions}\n",
    "\n",
    "for region in all_regions:\n",
    "    for scen in scen_to_pluck:\n",
    "\n",
    "        lbl_ovrlap_by_region[region][scen] = np.reshape(\n",
    "            gen_lbl_overlap(\n",
    "                Y_true_hand_lbl_by_region[region][scen],\n",
    "                Y_pred_hand_lbl_by_region[region][scen]),\n",
    "            (img_size, img_size, -1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Plot label overlap by region**\n",
    "\n",
    "First, reshape the labels into proper rasters for displaying"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_feat_dict = {'scenario_1_hand_lbl': 2,\n",
    "                 'scenario_2_hand_lbl': 4,\n",
    "                 'scenario_3_hand_lbl': 6}\n",
    "\n",
    "for region in all_regions:\n",
    "    for scen in scen_to_pluck:\n",
    "        Y_pred_hand_lbl_by_region[region][scen] = np.reshape(Y_pred_hand_lbl_by_region[region][scen],\n",
    "                                                             (img_size, img_size, -1))\n",
    "\n",
    "        Y_true_hand_lbl_by_region[region][scen] = np.reshape(Y_true_hand_lbl_by_region[region][scen],\n",
    "                                                             (img_size, img_size, -1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a function to plot the label overlap"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate color maps for the labels and label overlap\n",
    "\n",
    "from utils import general_utils\n",
    "\n",
    "wtr_cmap = general_utils.gen_cmap(['#f7f7f7', '#67a9cf'])\n",
    "ovrlp_cmap = general_utils.gen_cmap(['#67a9cf', '#f7f7f7', '#ef8a62', '#999999'])\n",
    "\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm\n",
    "fontprops = fm.FontProperties(size=15)\n",
    "\n",
    "def display_lbl_overlap(y_true, lbl_overlap, x_test, num_plot, region, indices=None):\n",
    "    \"\"\"\n",
    "    Function to display the label overlap\n",
    "    :param y_true: ndarray with ground truth labels\n",
    "    :param lbl_overlap: ndarray with label overlap\n",
    "    :param x_test: ndarray with Sentinel-1 co-event intensity (VH) raster\n",
    "    :param num_plot: integer, number of scenes to display\n",
    "    :param region: string with geographical region to display\n",
    "    :param indices: list of integer with indices to plot from the entire data set\n",
    "    :return: matplotlib figure handle\n",
    "    \"\"\"\n",
    "\n",
    "    fontprops = fm.FontProperties(size=12)\n",
    "\n",
    "    num_col = 5\n",
    "    fig, ax = plt.subplots(num_plot + 1, num_col, figsize=(20, 5 * num_plot))\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    if indices == None:\n",
    "        indices = range(num_plot)\n",
    "\n",
    "    for idx, raster in enumerate(indices):\n",
    "\n",
    "        ax[num_col * idx].imshow(x_test[region]['scenario_1_hand_lbl'][raster, :, :, 0], cmap='gray')\n",
    "        ax[num_col * idx].set_title(f'Co-event Intensity (VH)')\n",
    "\n",
    "        # plot ground truth\n",
    "        ax[num_col * idx + 1].imshow(y_true[region]['scenario_3_hand_lbl'][ :, :, raster], cmap=wtr_cmap)\n",
    "        ax[num_col * idx + 1].set_title(f'Ground Truth Label')\n",
    "\n",
    "        # plot scenario 1\n",
    "        ax[num_col * idx + 2].imshow(lbl_overlap[region]['scenario_1_hand_lbl'][:, :, raster], cmap=ovrlp_cmap)\n",
    "        ax[num_col * idx + 2].set_title('Scenario 1 Label Overlap')\n",
    "\n",
    "        # plot scenario 2\n",
    "        ax[num_col * idx + 3].imshow(lbl_overlap[region]['scenario_2_hand_lbl'][:, :, raster], cmap=ovrlp_cmap)\n",
    "        ax[num_col * idx + 3].set_title('Scenario 2 Label Overlap')\n",
    "\n",
    "        # plot scenario 3\n",
    "        ax[num_col * idx + 4].imshow(lbl_overlap[region]['scenario_3_hand_lbl'][:, :, raster], cmap=ovrlp_cmap)\n",
    "        ax[num_col * idx + 4].set_title('Scenario 3 Label Overlap')\n",
    "\n",
    "        for axis in ax[: num_col * num_plot]:\n",
    "            scalebar = AnchoredSizeBar(\n",
    "                axis.transData,\n",
    "                100,\n",
    "                '100m',\n",
    "                'lower left',\n",
    "                pad=0.1,\n",
    "                color='black',\n",
    "                frameon=False,\n",
    "                size_vertical=1,\n",
    "                fontproperties=fontprops)\n",
    "\n",
    "            axis.add_artist(scalebar)\n",
    "            axis.set_yticks([])\n",
    "            axis.set_xticks([]);\n",
    "\n",
    "    # Create legend\n",
    "    checkerboard = np.zeros((512, 512))\n",
    "    checkerboard[0:256, 0:256] = 1\n",
    "    checkerboard[256:, 0:256] = 2\n",
    "    checkerboard[0:256, 256:] = 3\n",
    "    checkerboard[256:, 256:] = 4\n",
    "\n",
    "\n",
    "    ax[num_col * idx + 4 + 3].imshow(checkerboard, cmap=ovrlp_cmap)\n",
    "    ax[num_col * idx + 4 + 3].text(50, 128, \"True Positives\", fontsize=8.);\n",
    "    ax[num_col * idx + 4 + 3].text(50, 384, \"True Negatives\", fontsize=8.);\n",
    "    ax[num_col * idx + 4 + 3].text(290, 128, \"False Positives\", fontsize=8.);\n",
    "    ax[num_col * idx + 4 + 3].text(290, 384, \"False Negatives\", fontsize=8.);\n",
    "    ax[num_col * idx + 4 + 3].set_yticks([])\n",
    "    ax[num_col * idx + 4 + 3].set_xticks([]);\n",
    "\n",
    "    ind_to_del = [1, 2, 4, 5]\n",
    "    for ind in ind_to_del:\n",
    "        fig.delaxes(ax[num_col * idx + 4 + ind])\n",
    "\n",
    "\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Label Overlap for Region: USA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ovrlp_lbl_pth = \"ovrlp_lbl_pth\"\n",
    "region = \"USA\"\n",
    "fname = f\"{ovrlp_lbl_pth}\\\\attn_unet_{region}_lbl_ovrlp.pdf\"\n",
    "\n",
    "idx_USA = [1, 3, 5, 8, 22]\n",
    "fig_USA = display_lbl_overlap(Y_true_hand_lbl_by_region,\n",
    "                              lbl_ovrlap_by_region,\n",
    "                              X_test_hand_lbl_by_region,\n",
    "                              num_plot=len(idx_USA),\n",
    "                              region='USA',\n",
    "                              indices=idx_USA)\n",
    "\n",
    "# save\n",
    "#fig_USA.savefig(fname)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Label Overlap for Region: Mekong"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "region = \"Mekong\"\n",
    "idx_Mekong = [1, 2, 5, 7, 8]\n",
    "fig_Mekong = display_lbl_overlap(Y_true_hand_lbl_by_region,\n",
    "                                 lbl_ovrlap_by_region,\n",
    "                                 X_test_hand_lbl_by_region,\n",
    "                                 num_plot=len(idx_Mekong),\n",
    "                                 region=region,\n",
    "                                 indices=idx_Mekong)\n",
    "\n",
    "#fname = f\"{ovrlp_lbl_pth}\\\\attn_unet_{region}_lbl_ovrlp.pdf\"\n",
    "#fig_Mekong.savefig(fname)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Label Overlap for Region: Bolivia"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "idx_Bolivia = [1, 2, 3, 4, 5]\n",
    "region = \"Bolivia\"\n",
    "fig_Bol = display_lbl_overlap(Y_true_hand_lbl_by_region,\n",
    "                              lbl_ovrlap_by_region,\n",
    "                              X_test_hand_lbl_by_region,\n",
    "                              num_plot=len(idx_Bolivia),\n",
    "                              region=region,\n",
    "                              indices=idx_Bolivia)\n",
    "\n",
    "fname = f\"{ovrlp_lbl_pth}\\\\attn_unet_{region}_lbl_ovrlp.pdf\"\n",
    "#fig_Bol.savefig(fname)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Label Overlap for Region: Paraguay"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "region = 'Paraguay'\n",
    "idx_Paraguay = [0, 1, 2, 6, 7]\n",
    "fig_Par = display_lbl_overlap(Y_true_hand_lbl_by_region,\n",
    "                              lbl_ovrlap_by_region,\n",
    "                              X_test_hand_lbl_by_region,\n",
    "                              num_plot=len(idx_Paraguay),\n",
    "                              region=region,\n",
    "                              indices=idx_Paraguay)\n",
    "\n",
    "\n",
    "fname = f\"{ovrlp_lbl_pth}\\\\attn_unet_{region}_lbl_ovrlp.pdf\"\n",
    "#fig_Par.savefig(fname)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Label Overlap for Region: India"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "region = \"India\"\n",
    "idx_India = [0, 2, 4, 6, 23]\n",
    "fig_Ind =display_lbl_overlap(Y_true_hand_lbl_by_region,\n",
    "                             lbl_ovrlap_by_region,\n",
    "                             X_test_hand_lbl_by_region,\n",
    "                             num_plot=len(idx_India),\n",
    "                             region=region,\n",
    "                             indices=idx_India)\n",
    "\n",
    "fname = f\"{ovrlp_lbl_pth}\\\\attn_unet_{region}_lbl_ovrlp.pdf\"\n",
    "#fig_Ind.savefig(fname)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Label Overlap for Region: Sri-Lanka"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "region = \"Sri-Lanka\"\n",
    "idx_Sri_Lanka = [8, 9, 11, 16, 21]\n",
    "fig_Sri = display_lbl_overlap(Y_true_hand_lbl_by_region,\n",
    "                              lbl_ovrlap_by_region,\n",
    "                              X_test_hand_lbl_by_region,\n",
    "                              num_plot=len(idx_Sri_Lanka),\n",
    "                              region=region,\n",
    "                              indices=idx_Sri_Lanka)\n",
    "\n",
    "fname = f\"{ovrlp_lbl_pth}\\\\attn_unet_{region}_lbl_ovrlp.pdf\"\n",
    "#fig_Sri.savefig(fname)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}